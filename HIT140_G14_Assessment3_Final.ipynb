{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASSESSMENT THREE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 | Setting up the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd                                     \n",
    "import numpy as np                                      \n",
    "import scipy.stats as st                                    \n",
    "import seaborn as sns                                   \n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as stats\n",
    "import math \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import anderson, ks_2samp\n",
    "from scipy.stats import mannwhitneyu\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Datasets into DataFrames\n",
    "dataset1 = pd.read_csv(\"dataset1.csv\")\n",
    "dataset2 = pd.read_csv(\"dataset2.csv\")\n",
    "dataset3 = pd.read_csv(\"dataset3.csv\")\n",
    "\n",
    "# Print Length of Each Dataset\n",
    "n = len(dataset1)\n",
    "print(\"The sample size is: %d\" % n)\n",
    "n = len(dataset2)\n",
    "print(\"The sample size is: %d\" % n)\n",
    "n = len(dataset3)\n",
    "print(\"The sample size is: %d\" % n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the Data\n",
    "print('Dataset 1 Preview: ')\n",
    "print(dataset1.head())\n",
    "\n",
    "print('\\nDataset 2 Preview: ')\n",
    "print(dataset2.head())\n",
    "\n",
    "print('\\nDataset 3 Preview: ')\n",
    "print(dataset3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Missing Values\n",
    "print('Missing Values in Dataset 1: ')\n",
    "print(dataset1.isnull().sum())\n",
    "\n",
    "print('\\nMissing Values in Dataset 2: ')\n",
    "print(dataset2.isnull().sum())\n",
    "\n",
    "print('\\nMissing Values in Dataset 3: ')\n",
    "print(dataset3.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics\n",
    "print('Descriptive Statistics Dataset 1: ')\n",
    "print(dataset1.describe())\n",
    "\n",
    "print('\\nDescriptive Statistics Dataset 2')\n",
    "print(dataset2.describe())\n",
    "\n",
    "print('\\nDescriptive Statistics Dataset 3')\n",
    "print(dataset3.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Datasets\n",
    "merged_data = dataset1.merge(dataset2, on='ID').merge(dataset3, on='ID')\n",
    "\n",
    "#Preview Merged Data\n",
    "print('Merged Data Keys: ')\n",
    "print(merged_data.keys())\n",
    "\n",
    "print('\\nMerged Data Types:')\n",
    "print(merged_data.dtypes)\n",
    "\n",
    "n = len(merged_data)\n",
    "print(\"\\nThe sample size is: %d\" % n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 1 | Gislene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Test for Gender Differences in Well-being\n",
    "2.1 Calculating the Overall Well-being Score\n",
    "\n",
    "Assuming each well-being indicator is equally important, we need to calculate the mean score for each individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of well-being columns\n",
    "wellbeing_cols = ['Optm', 'Usef', 'Relx', 'Intp', 'Engs', 'Dealpr', \n",
    "                  'Thcklr', 'Goodme', 'Clsep', 'Conf', 'Mkmind', \n",
    "                  'Loved', 'Intthg', 'Cheer']\n",
    "\n",
    "# Calculating the overall well-being\n",
    "merged_data['Overall_Wellbeing'] = merged_data[wellbeing_cols].mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Comparing Well-being Scores by Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating data by gender\n",
    "# Map gender codes to labels for clarity\n",
    "merged_data['Gender_Label'] = merged_data['gender'].map({0: 'Female', 1: 'Male'})\n",
    "\n",
    "# Separate well-being scores by gender\n",
    "female_wellbeing = merged_data[merged_data['Gender_Label'] == 'Female']['Overall_Wellbeing']\n",
    "male_wellbeing = merged_data[merged_data['Gender_Label'] == 'Male']['Overall_Wellbeing']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replaced with Georgia's the Anderson-Darling Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Anderson-Darling test for female and male well-being scores\n",
    "result_female = anderson(female_wellbeing.sample(10000, random_state=1))\n",
    "result_male = anderson(male_wellbeing.sample(10000, random_state=1))\n",
    "\n",
    "print(f\"Female group Anderson-Darling statistic: {result_female.statistic}\")\n",
    "print(f\"Male group Anderson-Darling statistic: {result_male.statistic}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Perform Mann-Whitney U Test\n",
    "Since the data is not normally distributed, we'll use a non-parametric test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_value = mannwhitneyu(female_wellbeing, male_wellbeing)\n",
    "print(f\"Mann-Whitney U p-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Significant difference in well-being between genders.\")\n",
    "else:\n",
    "    print(\"No significant difference in well-being between genders.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Visualising the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set white grid style and change palette\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"Blues_r\")\n",
    "\n",
    "# Boxplot of well-being scores by gender\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='Gender_Label', y='Overall_Wellbeing', data=merged_data)\n",
    "plt.title('Overall Well-being Scores by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Overall Well-being Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analysing Screen Time\n",
    "3.1 Calculate Total and Average Screen Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screen time columns\n",
    "screen_time_cols = ['C_wk', 'C_we', 'G_wk', 'G_we', 'S_wk', 'S_we', 'T_wk', 'T_we']\n",
    "\n",
    "# Total screen time per device\n",
    "merged_data['Total_Screen_Time'] = merged_data[screen_time_cols].sum(axis=1)\n",
    "\n",
    "# Average screen time per day\n",
    "merged_data['Avg_Screen_Time'] = merged_data['Total_Screen_Time'] / 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Analysing the Screen Time Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style and colour palette\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"Blues_r\")\n",
    "\n",
    "# Plot the histograms for total and average screen time\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Histogram for Total Screen Time\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(merged_data['Total_Screen_Time'], bins=30, kde=True)\n",
    "plt.title('Total Screen Time Distribution')\n",
    "plt.xlabel('Total Screen Time (hours)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Histogram for Average Screen Time\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(merged_data['Avg_Screen_Time'], bins=30, kde=True)\n",
    "plt.title('Average Screen Time per Day Distribution')\n",
    "plt.xlabel('Average Screen Time per Day (hours)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Note to Self:\n",
    "There is Outliers: The right-skewed tails suggest that there are outliers, so individuals with considerably high screen time compared to the majority. This may have implications when trying to understand the effect of screen time on well-being, as high users could drive differences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Sample code to identify outliers using IQR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = merged_data['Avg_Screen_Time'].quantile(0.25)\n",
    "Q3 = merged_data['Avg_Screen_Time'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Defining outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtering outliers\n",
    "outliers = merged_data[(merged_data['Avg_Screen_Time'] < lower_bound) | (merged_data['Avg_Screen_Time'] > upper_bound)]\n",
    "non_outliers = merged_data[(merged_data['Avg_Screen_Time'] >= lower_bound) & (merged_data['Avg_Screen_Time'] <= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Analysis with and without Outliers:\n",
    "Sample code for boxplots without outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style and colour palette\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"Blues_r\")\n",
    "\n",
    "# Create two subplots for with and without outliers\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot average screen time by gender with outliers\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x='Gender_Label', y='Avg_Screen_Time', data=merged_data)\n",
    "plt.title('Average Screen Time by Gender (With Outliers)')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Average Screen Time per Day (hours)')\n",
    "\n",
    "# Plot average screen time by gender without outliers\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x='Gender_Label', y='Avg_Screen_Time', data=non_outliers)\n",
    "plt.title('Average Screen Time by Gender (Without Outliers)')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Average Screen Time per Day (hours)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Comparing Screen Time by Gender and visualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann-Whitney U Test on screen time (without outliers)\n",
    "male_screen_time = non_outliers[non_outliers['Gender_Label'] == 'Male']['Avg_Screen_Time']\n",
    "female_screen_time = non_outliers[non_outliers['Gender_Label'] == 'Female']['Avg_Screen_Time']\n",
    "\n",
    "# Perform the test\n",
    "stat, p_value = mannwhitneyu(male_screen_time, female_screen_time)\n",
    "\n",
    "print(f\"Mann-Whitney U Test Statistic: {stat}\")\n",
    "print(f\"P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##visualizing the average screen time without outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean screen time by gender\n",
    "mean_screen_time = non_outliers.groupby('Gender_Label')['Avg_Screen_Time'].mean().reset_index()\n",
    "\n",
    "# Bar plot of mean screen time by gender\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Gender_Label', y='Avg_Screen_Time', data=mean_screen_time, palette=\"Blues_r\")\n",
    "plt.title('Average Screen Time by Gender (Without Outliers)')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Average Screen Time per Day (hours)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Assessing the Impact of Screen Time on Well-being 📊\n",
    "For determine how screen time affects well-being and see if there are gender differences in how screen time influences overall well-being scores.\n",
    "\n",
    "Notes: creating scatter plots of average screen time vs. overall well-being scores and Separating the scatter plots by gender to visually identify any patterns or relationships.\n",
    "\n",
    "Below code for Scatterplot (notes from class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for Screen Time vs. Well-being by Gender\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Scatter plot for females\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(x='Avg_Screen_Time', y='Overall_Wellbeing', data=non_outliers[non_outliers['Gender_Label'] == 'Female'])\n",
    "plt.title('Screen Time vs. Well-being (Females)')\n",
    "plt.xlabel('Average Screen Time (hours)')\n",
    "plt.ylabel('Overall Well-being Score')\n",
    "\n",
    "# Scatter plot for males\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(x='Avg_Screen_Time', y='Overall_Wellbeing', data=non_outliers[non_outliers['Gender_Label'] == 'Male'])\n",
    "plt.title('Screen Time vs. Well-being (Males)')\n",
    "plt.xlabel('Average Screen Time (hours)')\n",
    "plt.ylabel('Overall Well-being Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Interaction Between Screen Time, Gender, and Well-being"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Creating interaction term\n",
    "non_outliers['Gender_Numeric'] = non_outliers['Gender_Label'].map({'Female': 0, 'Male': 1})\n",
    "non_outliers['ScreenTime_Gender_Interaction'] = non_outliers['Avg_Screen_Time'] * non_outliers['Gender_Numeric']\n",
    "\n",
    "# Fit linear regression model\n",
    "model = smf.ols('Overall_Wellbeing ~ Avg_Screen_Time + Gender_Numeric + ScreenTime_Gender_Interaction', data=non_outliers).fit()\n",
    "\n",
    "# Print summary of the regression model\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 Feature Engineering applied to merged_data\n",
    "\n",
    "# Create interaction term between gender and screen time\n",
    "merged_data['Gender_Numeric'] = merged_data['Gender_Label'].map({'Female': 0, 'Male': 1})\n",
    "merged_data['ScreenTime_Gender_Interaction'] = merged_data['Avg_Screen_Time'] * merged_data['Gender_Numeric']\n",
    "\n",
    "# Identify primary device\n",
    "screen_time_cols = ['C_wk', 'G_wk', 'S_wk', 'T_wk']\n",
    "merged_data['Primary_Device'] = merged_data[screen_time_cols].idxmax(axis=1)\n",
    "\n",
    "# Encode primary device as categorical\n",
    "primary_device_dummies = pd.get_dummies(merged_data['Primary_Device'], prefix='Primary_Device')\n",
    "merged_data = pd.concat([merged_data, primary_device_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build the Predictive Models\n",
    "\n",
    "5.1 Preparing the Data for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#In this step, we will define the features and target variables for the predictive model.\n",
    " #We will also prepare the data by splitting it into training and testing sets.\n",
    "\n",
    "\n",
    "# Features for modeling\n",
    "features = ['Gender_Numeric', 'Total_Screen_Time', 'ScreenTime_Gender_Interaction'] + \\\n",
    "           [col for col in merged_data.columns if 'Primary_Device_' in col]\n",
    "\n",
    "# Target variable\n",
    "target = 'Overall_Wellbeing'\n",
    "\n",
    "# Define X and y\n",
    "X = merged_data[features]\n",
    "y = merged_data[target]\n",
    "\n",
    "# One-hot encode categorical variables (if not already done)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Building a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5.2: \n",
    "# creating a Linear Regression model to predict well-being scores using our selected features.\n",
    "# also evaluating the model's performance with R-squared and Mean Squared Error (MSE).\n",
    "\n",
    "# Load the data (as feature engineering has already been performed)\n",
    "# Note: Replace 'data_with_features.csv' with the actual path to our feature-engineered dataset\n",
    "data = pd.read_csv('data_with_features.csv')\n",
    "\n",
    "# Features for modelling\n",
    "features = ['Gender_Numeric', 'Total_Screen_Time', 'ScreenTime_Gender_Interaction'] + \\\n",
    "           [col for col in data.columns if 'Primary_Device_' in col]\n",
    "\n",
    "# Target variable\n",
    "target = 'Overall_Wellbeing'\n",
    "\n",
    "# Define X and y\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# One-hot encode categorical variables \n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialise the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict well-being scores on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Interpreting the Model Coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model coefficients\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model.coef_\n",
    "})\n",
    "\n",
    "# Add interpretation column\n",
    "coefficients['Impact'] = coefficients['Coefficient'].apply(lambda x: 'Positive' if x > 0 else 'Negative')\n",
    "\n",
    "# Sort coefficients by their impact\n",
    "coefficients = coefficients.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Print the coefficients DataFrame\n",
    "print(coefficients)\n",
    "\n",
    "# Print the intercept\n",
    "print(f'Intercept: {model.intercept_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Visualising Actual vs. Predicted Well-being\n",
    " see how well our model's predictions match the actual well-being scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for dark background\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "# Plotting Actual vs Predicted Well-being Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
    "\n",
    "# Plotting the ideal line for comparison (where Actual = Predicted)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Actual Well-being Scores')\n",
    "plt.ylabel('Predicted Well-being Scores')\n",
    "plt.title('Actual vs. Predicted Well-being Scores')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Evaluating the Effect of Primary Device\n",
    "see how the primary device used influences overall well-being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Creating Interaction Term \n",
    "# Note: remember to make sure to replace 'gender' and 'Total_Screen_Time' with the appropriate column names in the dataset\n",
    "merged_data['Gender_TotalScreenTime'] = merged_data['gender'] * merged_data['Total_Screen_Time']\n",
    "\n",
    "# Step 2: Determine the Primary Device Used (based on maximum usage hours)\n",
    "device_columns = ['C_we', 'C_wk', 'G_we', 'G_wk', 'S_we', 'S_wk', 'T_we', 'T_wk']\n",
    "merged_data['Primary_Device'] = merged_data[device_columns].idxmax(axis=1)\n",
    "\n",
    "# Step 3: Create Dummy Variables for the Primary Device\n",
    "merged_data = pd.get_dummies(merged_data, columns=['Primary_Device'], drop_first=True)\n",
    "\n",
    "# Step 4: Preparing Features for Regression\n",
    "# Update the features list to include 'Gender_TotalScreenTime'\n",
    "features = ['gender', 'Total_Screen_Time', 'Gender_TotalScreenTime'] + \\\n",
    "           [col for col in merged_data.columns if 'Primary_Device_' in col]\n",
    "\n",
    "# Step 5: Define X and y\n",
    "X = merged_data[features]\n",
    "y = merged_data['Overall_Wellbeing']\n",
    "\n",
    "# Step 6: Split Data into Train and Test Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 7: Train the Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Evaluate the Model\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Print Model R-squared and Mean Squared Error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print('R-squared:', r2_score(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Step 9: Get Model Coefficients\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': lr_model.coef_\n",
    "})\n",
    "coefficients['Impact'] = coefficients['Coefficient'].apply(lambda x: 'Positive' if x > 0 else 'Negative')\n",
    "print(coefficients)\n",
    "\n",
    "# Print the intercept\n",
    "print(f'Intercept: {lr_model.intercept_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Statistical Analysis of Primary Device Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the columns present in the DataFrame\n",
    "print(\"Available columns in merged_data:\")\n",
    "print(merged_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns representing screen time for each device\n",
    "device_columns = ['C_we', 'C_wk', 'G_we', 'G_wk', 'S_we', 'S_wk', 'T_we', 'T_wk']\n",
    "\n",
    "# Create a column that shows the primary device with the maximum usage time for each respondent\n",
    "merged_data['Primary_Device'] = merged_data[device_columns].idxmax(axis=1)\n",
    "\n",
    "# Confirm that the column was created successfully\n",
    "print(merged_data[['ID', 'Primary_Device']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Kruskal-Wallis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Extracting well-being scores for each primary device group\n",
    "primary_devices = merged_data['Primary_Device'].unique()\n",
    "wellbeing_scores = [merged_data[merged_data['Primary_Device'] == device]['Overall_Wellbeing'] for device in primary_devices]\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "stat, p_value = kruskal(*wellbeing_scores)\n",
    "\n",
    "print(f\"Kruskal-Wallis test statistic: {stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in well-being scores among different primary device groups (Reject H0).\")\n",
    "else:\n",
    "    print(\"There is no significant difference in well-being scores among different primary device groups (Fail to reject H0).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Visualising the Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style for a dark background\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "# Boxplot for Well-being Scores by Primary Device\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Primary_Device', y='Overall_Wellbeing', data=merged_data)\n",
    "plt.title('Well-being Scores by Primary Device')\n",
    "plt.xlabel('Primary Device')\n",
    "plt.ylabel('Well-being Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Interaction Between Gender and Primary Device\n",
    "Two-Way ANOVA to Check Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Variables to Categorical\n",
    "merged_data['Gender_Label'] = merged_data['Gender_Label'].astype('category')\n",
    "merged_data['Primary_Device'] = merged_data['Primary_Device'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Missing or Empty Groups\n",
    "print(merged_data.groupby(['Gender_Label', 'Primary_Device']).size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Recreating Primary_Device Correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Primary_Device based on max screen time columns\n",
    "screen_time_cols = ['C_we', 'C_wk', 'G_we', 'G_wk', 'S_we', 'S_wk', 'T_we', 'T_wk']\n",
    "merged_data['Primary_Device'] = merged_data[screen_time_cols].idxmax(axis=1)\n",
    "merged_data['Primary_Device'] = merged_data['Primary_Device'].str.extract(r'([A-Z])')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rerun the ANOVA\n",
    "merged_data['Primary_Device'] = merged_data['Primary_Device'].astype('category')\n",
    "\n",
    "# Running the two-way ANOVA again\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "model = ols('Overall_Wellbeing ~ Gender_Label * Primary_Device', data=merged_data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Visualising the Interaction Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the style for dark background\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "# Plotting interaction between Gender and Primary Device\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Primary_Device', y='Overall_Wellbeing', hue='Gender_Label', data=merged_data, palette='Blues_r')\n",
    "plt.title('Interaction Effect of Gender and Primary Device on Well-being Scores')\n",
    "plt.xlabel('Primary Device')\n",
    "plt.ylabel('Overall Well-being Score')\n",
    "plt.legend(title='Gender')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 2 | Georgia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A | Ethnic Groups + Well-being Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 | Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Majority Ethnic Group & Minority Ethnic Group\n",
    "# Ethnic group labels\n",
    "merged_data['ethnic_group'] = merged_data['minority'].map({0: 'Majority', 1: 'Minority'})\n",
    "\n",
    "# Filter the data into majority/minority groups\n",
    "majority_data = merged_data[merged_data['minority'] == 0]\n",
    "minority_data = merged_data[merged_data['minority'] == 1]\n",
    "\n",
    "# Preview Ethnic Group Data\n",
    "print('Filtered Data - Majority: (%.d rows and %.d columns.)' % (majority_data.shape[0], majority_data.shape[1]))\n",
    "print('Filtered Data - Minority: (%.d rows and %.d columns.)' % (minority_data.shape[0], minority_data.shape[1]))\n",
    "\n",
    "print('Majority Group Preview: ')\n",
    "print(majority_data.head())\n",
    "\n",
    "print('\\nMinority Group Preview: ')\n",
    "print(minority_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Well-being\n",
    "# Well-being Columns\n",
    "wellbeing = ['Optm', 'Usef', 'Relx', 'Intp', 'Engs', 'Dealpr', 'Thcklr', 'Goodme', 'Clsep', 'Conf', 'Mkmind', 'Loved', 'Intthg', 'Cheer']\n",
    "\n",
    "# Well-being Mean\n",
    "merged_data['overall_wellbeing'] = merged_data[wellbeing].mean(axis=1)\n",
    "\n",
    "# Create DataFrame for majority/minority well-being scores\n",
    "majority_wellbeing = majority_data[wellbeing]\n",
    "minority_wellbeing = minority_data[wellbeing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority Descriptive Statistics\n",
    "# Compute means\n",
    "wellbeing_means_majority = majority_data[wellbeing].mean()\n",
    "\n",
    "print('Mean Scores for Each Wellbeing Indicator (Majority Group):')\n",
    "for indicator, mean in wellbeing_means_majority.items():\n",
    "    print(f'{indicator}: {mean:.2f}')\n",
    "\n",
    "# Compute overall mean\n",
    "overall_wellbeing_mean_majority = wellbeing_means_majority.mean()\n",
    "\n",
    "print('\\nOverall Wellbeing Mean (Majority Group): %.2f' % overall_wellbeing_mean_majority)\n",
    "print()\n",
    "\n",
    "# Minority Descriptive Statistics\n",
    "# Compute means\n",
    "wellbeing_means_minority = minority_data[wellbeing].mean()\n",
    "\n",
    "print('Mean Scores for Each Wellbeing Indicator (Minority Group):')\n",
    "for indicator, mean in wellbeing_means_minority.items():\n",
    "    print(f'{indicator}: {mean:.2f}')\n",
    "\n",
    "# Compute overall mean\n",
    "overall_wellbeing_mean_minority = wellbeing_means_minority.mean()\n",
    "\n",
    "print('\\nOverall Wellbeing Mean (Minority Group): %.2f' % overall_wellbeing_mean_minority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.style.use('default') \n",
    "\n",
    "# Data Visualisation | Bar Plots\n",
    "wellbeing_means_majority = pd.Series([3.26, 3.09, 3.11, 3.32, 3.04, 3.37, 3.48, 3.24, 3.58, 3.27, 3.86, 3.93, 3.44, 3.50], \n",
    "                                      index=['Optm', 'Usef', 'Relx', 'Intp', 'Engs', 'Dealpr', 'Thcklr', 'Goodme', 'Clsep', 'Conf', 'Mkmind', 'Loved', 'Intthg', 'Cheer'])\n",
    "\n",
    "wellbeing_means_minority = pd.Series([3.35, 3.18, 3.05, 3.10, 3.06, 3.37, 3.52, 3.38, 3.47, 3.44, 3.83, 3.81, 3.60, 3.49], \n",
    "                                      index=['Optm', 'Usef', 'Relx', 'Intp', 'Engs', 'Dealpr', 'Thcklr', 'Goodme', 'Clsep', 'Conf', 'Mkmind', 'Loved', 'Intthg', 'Cheer'])\n",
    "\n",
    "# Sub-plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Majority Mean Well-Being Scores\n",
    "axes[0].bar(wellbeing_means_majority.index, wellbeing_means_majority.values, color='#BC5090')\n",
    "axes[0].set_title('Mean Well-being Score (Majority Group)', fontsize=16, fontweight='bold', color='#BC5090')\n",
    "axes[0].set_xlabel('Well-being Indicator', fontsize=14, fontweight='bold', color='#BC5090')\n",
    "axes[0].set_ylabel('Mean Score', fontsize=14, fontweight='bold', color='#BC5090')\n",
    "axes[0].set_ylim(0, 6)\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "for index, value in enumerate(wellbeing_means_majority.values):\n",
    "    axes[0].text(index, value + 0.1, f'{value:.2f}', ha='center', fontsize=12,color='#003F5C')\n",
    "\n",
    "# Minority Mean Well-Being Scores\n",
    "axes[1].bar(wellbeing_means_minority.index, wellbeing_means_minority.values, color='#58508D')\n",
    "axes[1].set_title('Mean Well-being Score (Minority Group)', fontsize=16, fontweight='bold', color='#58508D')\n",
    "axes[1].set_xlabel('Well-being Indicator', fontsize=14, fontweight='bold', color='#58508D')\n",
    "axes[1].set_ylabel('Mean Score', fontsize=14, fontweight='bold', color='#58508D')\n",
    "axes[1].set_ylim(0, 6)\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "for index, value in enumerate(wellbeing_means_minority.values):\n",
    "    axes[1].text(index, value + 0.1, f'{value:.2f}', ha='center', fontsize=12, color='#003F5C')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 | Test for Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk Test\n",
    "df_majority = majority_wellbeing.sample(5000, random_state=1)\n",
    "df_minority = minority_wellbeing.sample(5000, random_state=1)\n",
    "\n",
    "_, p_majority = shapiro(df_majority)\n",
    "_, p_minority = shapiro(df_minority)\n",
    "\n",
    "print('Majority Group Normality p-value: ', p_majority) \n",
    "print('Minority Group Normality p-value: ', p_minority)\n",
    "print() \n",
    "\n",
    "if p_majority < 0.05:\n",
    "        print('Majority Group Data is not normally distributed.')\n",
    "else:\n",
    "        print('Majority Group Data is normally distributed.')\n",
    "\n",
    "        \n",
    "if p_minority < 0.05:\n",
    "        print('Minority Group Data is not normally distributed.')\n",
    "else:\n",
    "        print('Minority Group Data is normally distributed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anderson-Darling Test\n",
    "# Calculate the mean scores for the selected columns for both groups\n",
    "majority_wellbeing_mean = merged_data[merged_data['minority'] == 0][['Optm', 'Usef', 'Relx', 'Intp', 'Engs', 'Dealpr', 'Thcklr', 'Goodme', 'Clsep', 'Conf', 'Mkmind', 'Loved', 'Intthg', 'Cheer']].mean(axis=1) \n",
    "minority_wellbeing_mean = merged_data[merged_data['minority'] == 1][['Optm', 'Usef', 'Relx', 'Intp', 'Engs', 'Dealpr', 'Thcklr', 'Goodme', 'Clsep', 'Conf', 'Mkmind', 'Loved', 'Intthg', 'Cheer']].mean(axis=1) \n",
    "\n",
    "# Perform the A-D test on the means\n",
    "result1 = anderson(majority_wellbeing_mean.dropna())\n",
    "result2 = anderson(minority_wellbeing_mean.dropna())\n",
    "\n",
    "# Perform Kolmogorov-Smirnov test to compare samples\n",
    "ks_statistic, ks_p_value = ks_2samp(majority_wellbeing_mean.dropna(), minority_wellbeing_mean.dropna())\n",
    "print('\\nKS Statistic:', ks_statistic)\n",
    "print('P-value:', ks_p_value)\n",
    "\n",
    "if ks_p_value < 0.05:\n",
    "    print('The distributions of the two groups are significantly different.')\n",
    "else:\n",
    "    print('The distributions of the two groups are not significantly different.')\n",
    "\n",
    "# Print distribution outcome based on A-D test\n",
    "if result1.statistic > result1.critical_values[2]:\n",
    "    print('Majority Group Data is not normally distributed.')\n",
    "else:\n",
    "    print('Majority Group Data is normally distributed.')\n",
    "\n",
    "if result2.statistic > result2.critical_values[2]:\n",
    "    print('Minority Group Data is not normally distributed.')\n",
    "else:\n",
    "    print('Minority Group Data is normally distributed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 | Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann-Whitney U Test\n",
    "p_values = []\n",
    "for column in wellbeing: \n",
    "        stat, p_val = mannwhitneyu(majority_data[column], minority_data[column])\n",
    "        p_values.append(p_val)\n",
    "        print(f\"Mann-Whitney U p-value for {column}: \", p_val)\n",
    "\n",
    "\n",
    "        if p_val < 0.05:\n",
    "                print(f'There is a statistically significant difference in {column} scores between ethnicity groups.')\n",
    "        else:\n",
    "                print(f'There is no statistically significant difference in {column} scores between ethnicity groups.')\n",
    "        print()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect Sizes\n",
    "def mann_whitney_effect_size(u, n1, n2):\n",
    "    return (u / (n1 * n2)) - 0.5\n",
    "\n",
    "n_majority = majority_data.shape[0]\n",
    "n_minority = minority_data.shape[0]\n",
    "\n",
    "for column in wellbeing: \n",
    "    stat, p_val = mannwhitneyu(majority_data[column], minority_data[column])\n",
    "    u = stat\n",
    "    effect_size = mann_whitney_effect_size(u, n_majority, n_minority)\n",
    "    \n",
    "    \n",
    "    if effect_size < 0.1:\n",
    "        interpretation = 'small'\n",
    "    elif effect_size < 0.3:\n",
    "        interpretation = 'medium'\n",
    "    elif effect_size >= 0.5:\n",
    "        interpretation = 'large'\n",
    "    else:\n",
    "        interpretation = 'between medium and large'\n",
    "    \n",
    "    print(f\"Effect size for {column}: {effect_size:.3f} ({interpretation})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualisation | Box Plot\n",
    "wellbeing_long = merged_data.melt(id_vars='ethnic_group', value_vars=wellbeing, var_name='Wellbeing Indicator', value_name='Score')\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Wellbeing Indicator', y='Score', hue='ethnic_group', data=wellbeing_long, palette={'Majority': '#BC5090', 'Minority': '#58508D'})\n",
    "plt.title('Wellbeing Scores Across Ethnic Groups', fontsize=16, fontweight='bold', color='#003F5C')\n",
    "plt.xlabel('Wellbeing Indicator', fontsize=14, fontweight='bold', color='#003F5C')\n",
    "plt.ylabel('Score', fontsize=14, fontweight='bold', color='#003F5C')\n",
    "plt.xticks(rotation=45, fontsize=12, color='#003F5C')\n",
    "plt.legend(title='Ethnic Group', title_fontsize='13', fontsize='12')\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.ylim(wellbeing_long['Score'].min() - 0.5, wellbeing_long['Score'].max() + 0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B | Ethnic Groups + Screen Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 | Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Screen Time\n",
    "# Device + Screen Time Columns\n",
    "screentime = ['C_wk', 'C_we', 'G_wk', 'G_we', 'S_wk', 'S_we', 'T_wk', 'T_we']\n",
    "\n",
    "# Screen Time Mean\n",
    "merged_data['overall_screentime'] = merged_data[screentime].mean(axis=1)\n",
    "\n",
    "# Create DataFrame for majority/minority well-being scores\n",
    "majority_screentime = majority_data[screentime]\n",
    "minority_screentime = minority_data[screentime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority Descriptive Statistics\n",
    "# Compute means\n",
    "screentime_means_majority = majority_data[screentime].mean()\n",
    "\n",
    "print('Mean Hours for Each Device (Majority Group):')\n",
    "for indicator, mean in screentime_means_majority.items():\n",
    "    print(f'{indicator}: {mean:.2f}')\n",
    "\n",
    "# Compute overall mean\n",
    "overall_screentime_mean_majority = screentime_means_majority.mean()\n",
    "\n",
    "print('\\nOverall Screen Time Mean (Majority Group): %.2f' % overall_screentime_mean_majority)\n",
    "print()\n",
    "\n",
    "# Minority Descriptive Statistics\n",
    "# Compute means\n",
    "screentime_means_minority = minority_data[screentime].mean()\n",
    "\n",
    "print('Mean Hours for Each Device (Minority Group):')\n",
    "for indicator, mean in screentime_means_minority.items():\n",
    "    print(f'{indicator}: {mean:.2f}')\n",
    "\n",
    "# Compute overall mean\n",
    "overall_screentime_mean_minority = screentime_means_minority.mean()\n",
    "\n",
    "print('\\nOverall Screen Time Mean (Minority Group): %.2f' % overall_screentime_mean_minority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualisation | Bar Plots\n",
    "screentime_means_majority = pd.Series([1.71, 2.13, 1.08, 1.80, 2.91, 3.51, 2.56, 3.60], \n",
    "                                      index=['C_we', 'C_wk', 'G_we', 'G_wk', 'S_we', 'S_wk', 'T_we', 'T_wk'])\n",
    "\n",
    "screentime_means_minority = pd.Series([1.95, 2.44, 0.71, 1.47, 2.81, 3.49, 2.53, 3.82], \n",
    "                                      index=['C_we', 'C_wk', 'G_we', 'G_wk', 'S_we', 'S_wk', 'T_we', 'T_wk'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Majority Mean Screen Time \n",
    "axes[0].bar(screentime_means_majority.index, screentime_means_majority.values, color='#BC5090', label='Majority Group')\n",
    "axes[0].set_title('Majority Ethnic Group Mean Hours of Screen Time', fontsize=16, fontweight='bold', color='#BC5090')\n",
    "axes[0].set_xlabel('Device', fontsize=14, color='#BC5090', fontweight='bold')\n",
    "axes[0].set_ylabel('Mean Hours', fontsize=14, color='#BC5090', fontweight='bold')\n",
    "axes[0].set_ylim(0, 6)\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "for index, value in enumerate(screentime_means_majority.values):\n",
    "    axes[0].text(index, value + 0.1, f'{value:.2f}', ha='center', fontsize=12, color='#003F5C')\n",
    "\n",
    "# Minority Mean Screen Time\n",
    "axes[1].bar(screentime_means_minority.index, screentime_means_minority.values, color='#58508D', label='Minority Group')\n",
    "axes[1].set_title('Minority Ethnic Group Mean Hours of Screen Time', fontsize=16, fontweight='bold', color='#58508D')\n",
    "axes[1].set_xlabel('Device', fontsize=14, color='#58508D', fontweight='bold')\n",
    "axes[1].set_ylabel('Mean Hours', fontsize=14, color='#58508D', fontweight='bold')\n",
    "axes[1].set_ylim(0, 6)\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "for index, value in enumerate(screentime_means_minority.values):\n",
    "    axes[1].text(index, value + 0.1, f'{value:.2f}', ha='center', fontsize=12, color='#003F5C')\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 | Test for Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk Test\n",
    "df_majority = majority_screentime.sample(5000, random_state=1)\n",
    "df_minority = minority_screentime.sample(5000, random_state=1)\n",
    "\n",
    "_, p_majority = shapiro(df_majority)\n",
    "_, p_minority = shapiro(df_minority)\n",
    "\n",
    "print('Majority Group Normality p-value: ', p_majority) \n",
    "print('Minority Group Normality p-value: ', p_minority)\n",
    "print() \n",
    "\n",
    "if p_majority < 0.05:\n",
    "        print('Majority Group Data is not normally distributed.')\n",
    "else:\n",
    "        print('Majority Group Data is normally distributed.')\n",
    "\n",
    "        \n",
    "if p_minority < 0.05:\n",
    "        print('Minority Group Data is not normally distributed.')\n",
    "else:\n",
    "        print('Minority Group Data is normally distributed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anderson-Darling Test\n",
    "# Calculate the mean scores for the selected columns for both groups\n",
    "majority_screentime_mean = merged_data[merged_data['minority'] == 0][['C_wk', 'C_we', 'G_wk', 'G_we', 'S_wk', 'S_we', 'T_wk', 'T_we']].mean(axis=1) \n",
    "minority_screentime_mean = merged_data[merged_data['minority'] == 1][['C_wk', 'C_we', 'G_wk', 'G_we', 'S_wk', 'S_we', 'T_wk', 'T_we']].mean(axis=1) \n",
    "\n",
    "# Perform the A-D test on the means\n",
    "result1 = anderson(majority_screentime_mean.dropna())\n",
    "result2 = anderson(minority_screentime_mean.dropna())\n",
    "\n",
    "# Perform Kolmogorov-Smirnov test to compare samples\n",
    "ks_statistic, ks_p_value = ks_2samp(majority_screentime_mean.dropna(), minority_screentime_mean.dropna())\n",
    "print('\\nKS Statistic:', ks_statistic)\n",
    "print('P-value:', ks_p_value)\n",
    "\n",
    "if ks_p_value < 0.05:\n",
    "    print('The distributions of the two groups are significantly different.')\n",
    "else:\n",
    "    print('The distributions of the two groups are not significantly different.')\n",
    "\n",
    "# Print distribution outcome based on A-D test\n",
    "if result1.statistic > result1.critical_values[2]:\n",
    "    print('Majority Group Data is not normally distributed.')\n",
    "else:\n",
    "    print('Majority Group Data is normally distributed.')\n",
    "\n",
    "if result2.statistic > result2.critical_values[2]:\n",
    "    print('Minority Group Data is not normally distributed.')\n",
    "else:\n",
    "    print('Minority Group Data is normally distributed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 | Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Mann-Whitney U Test\n",
    "p_values = []\n",
    "for column in screentime: \n",
    "        stat, p_val = mannwhitneyu(majority_data[column], minority_data[column])\n",
    "        p_values.append(p_val)\n",
    "        print(f\"Mann-Whitney U p-value for {column}: \", p_val)\n",
    "\n",
    "        if p_val < 0.05:\n",
    "                print(f'There is a statistically significant difference in {column} hours between ethnicity groups.')\n",
    "        else:\n",
    "                print(f'There is no statistically significant difference in {column} hours between ethnicity groups.')\n",
    "        print()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect Sizes\n",
    "def mann_whitney_effect_size(u, n1, n2):\n",
    "    return (u / (n1 * n2)) - 0.5\n",
    "\n",
    "n_majority = majority_data.shape[0]\n",
    "n_minority = minority_data.shape[0]\n",
    "\n",
    "for column in screentime: \n",
    "    stat, p_val = mannwhitneyu(majority_data[column], minority_data[column])\n",
    "    u = stat\n",
    "    effect_size = mann_whitney_effect_size(u, n_majority, n_minority)\n",
    "    \n",
    "    \n",
    "    if effect_size < 0.1:\n",
    "        interpretation = 'small'\n",
    "    elif effect_size < 0.3:\n",
    "        interpretation = 'medium'\n",
    "    elif effect_size >= 0.5:\n",
    "        interpretation = 'large'\n",
    "    else:\n",
    "        interpretation = 'between medium and large'\n",
    "    \n",
    "    print(f\"Effect size for {column}: {effect_size:.3f} ({interpretation})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualisation | Box Plot\n",
    "# Melt data\n",
    "screentime_long = merged_data.melt(id_vars='ethnic_group', value_vars=screentime, var_name='Device', value_name='Hours')\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Device', y='Hours', hue='ethnic_group', data=screentime_long, palette={'Majority': '#BC5090', 'Minority': '#58508D'})\n",
    "\n",
    "plt.title('Screen Time Across Ethnic Groups', fontsize=16, fontweight='bold', color='#003F5C')\n",
    "plt.xlabel('Device', fontsize=14, fontweight='bold', color='#003F5C')\n",
    "plt.ylabel('Hours', fontsize=14, fontweight='bold', color='#003F5C')\n",
    "plt.xticks(rotation=45, fontsize=12, color='#003F5C')\n",
    "plt.legend(title='Ethnic Group', title_fontsize='13', fontsize='12')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.ylim(0, screentime_long['Hours'].max() + 1) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C | Predictive Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the Minority Data into DataFrame\n",
    "minority_data = merged_data[merged_data['minority'] == 1]\n",
    "\n",
    "n = len(minority_data)\n",
    "print(\"The sample size is: %d\" % n)\n",
    "\n",
    "print(minority_data.columns)\n",
    "\n",
    "# Create new DataFrame\n",
    "minority_df = minority_data.copy()\n",
    "\n",
    "minority_df['wellbeing'] = minority_data[['Optm', 'Usef', 'Relx', 'Intp', 'Engs', 'Dealpr', 'Thcklr', 'Goodme', 'Clsep', 'Conf', 'Mkmind', 'Loved', 'Intthg', 'Cheer']].mean(axis=1)\n",
    "\n",
    "minority_df['screentime'] = minority_data[[\"C_we\", \"C_wk\", \"G_we\", \"G_wk\", \"S_we\", \"S_wk\", \"T_we\", \"T_wk\"]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample size\n",
    "n = len(minority_df)\n",
    "print(f\"The sample size is: {n}\")\n",
    "\n",
    "# Confirm means\n",
    "wellbeing_mean = minority_df['wellbeing'].mean()\n",
    "screentime_mean = minority_df['screentime'].mean()\n",
    "\n",
    "# Print results\n",
    "print(f\"Minority Wellbeing Mean: {wellbeing_mean:.2f}\")\n",
    "print(f\"Minority Screen Time Mean: {screentime_mean:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation with Pearson's R\n",
    "correlation_matrix = minority_df[['screentime', 'wellbeing']].corr(method='pearson')\n",
    "\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Data Visualisation | Heatmap\n",
    "colors = ['#BC5090', '#58508D', '#003F5C'] \n",
    "custom_cmap = LinearSegmentedColormap.from_list('custom', colors)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=custom_cmap, cbar=True, square=True, fmt=\".2f\")\n",
    "plt.title('Pearson Correlation Matrix Heatmap', fontsize=16, fontweight='bold', color='#003F5C')\n",
    "plt.xticks(fontsize=12, color='#003F5C')\n",
    "plt.yticks(fontsize=12, color='#003F5C')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualisation | Scatterplot \n",
    "sns.lmplot(x='wellbeing', y='screentime', data=minority_df, height=6, aspect=1.25, \n",
    "           scatter_kws={'s': 2.5, 'alpha': 0.6}, line_kws={'color': '#BC5090', 'linewidth': 3})\n",
    "\n",
    "plt.xlabel('Well-being', fontsize=14, fontweight='bold', color='#003F5C')\n",
    "plt.ylabel('Screen Time', fontsize=14, fontweight='bold', color='#003F5C')\n",
    "plt.title('Relationship between Screen Time and Well-being (Minority Group)', fontsize=16, fontweight='bold', color='#003F5C')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The outcome of this shows there is a very small, negative relationship between screentime and well-being for minority group. Therefore, Linear Regression Model may not be the most appropriate model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9 | Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation screen time\n",
    "minority_df['log_screentime'] = np.log(minority_df['screentime'] + 1)\n",
    "\n",
    "# Review distribution \n",
    "sample = minority_df['log_screentime'].sample(5000, random_state=1)\n",
    "stat, p_value = shapiro(sample)\n",
    "if p_value < 0.05:\n",
    "    print(\"Data is not normally distributed\")\n",
    "    print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation Well-being\n",
    "minority_df['log_wellbeing'] = np.log(minority_df['wellbeing'] + 1)\n",
    "\n",
    "# Review distribution\n",
    "sample = minority_df['log_wellbeing'].sample(5000, random_state=1)\n",
    "stat, p_value = shapiro(sample)\n",
    "if p_value < 0.05:\n",
    "    print(\"Data is not normally distributed\")\n",
    "    print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation with Pearson's R\n",
    "correlation_matrix = minority_df[['log_screentime', 'log_wellbeing']].corr(method='pearson')\n",
    "\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Data Visualisation | Heatmap\n",
    "colors = ['#BC5090', '#58508D', '#003F5C'] \n",
    "custom_cmap = LinearSegmentedColormap.from_list('custom', colors)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=custom_cmap, cbar=True, square=True, fmt=\".2f\")\n",
    "plt.title('Pearson Correlation Matrix Heatmap', fontsize=16, fontweight='bold', color='#003F5C')\n",
    "plt.xticks(fontsize=12, color='#003F5C')\n",
    "plt.yticks(fontsize=12, color='#003F5C')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualisation | Scatterplot \n",
    "sns.lmplot(x='log_wellbeing', y='log_screentime', data=minority_df, height=6, aspect=1.25, \n",
    "           scatter_kws={'s': 2.5, 'alpha': 0.6}, line_kws={'color': '#BC5090', 'linewidth': 3})\n",
    "\n",
    "plt.xlabel('Log Well-being', fontsize=14, fontweight='bold', color='#003F5C')\n",
    "plt.ylabel('Log Screen Time', fontsize=14, fontweight='bold', color='#003F5C')\n",
    "plt.title('Relationship between Log Screen Time and Log Well-being (Minority Group)', fontsize=16, fontweight='bold', color='#003F5C')\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate variables\n",
    "x = minority_df['log_screentime'].values.reshape(-1, 1) \n",
    "y = minority_df['log_wellbeing'].values\n",
    "\n",
    "# Split dataset into training (60%) and testing (40%) \n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=0)\n",
    "\n",
    "# Build LRM\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train (fit) the LRM using training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print intercept and coefficient from LRM\n",
    "print(\"Intercept: \", model.intercept_)\n",
    "print(\"Coefficient: \", model.coef_)\n",
    "\n",
    "# Use LRM to predict values of (y)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Show predicted values of (y) next to the actual values of (y)\n",
    "df_pred = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred})\n",
    "print(df_pred)\n",
    "\n",
    "# Compute standard performance metrics of LRM\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "rmse_norm = rmse / (y.max() - y.min())\n",
    "r_2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Multiple Linear P performance:\")\n",
    "print(\"MAE: \", mae)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"RMSE (Normalised): \", rmse_norm)\n",
    "print(\"R^2: \", r_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_data = {\n",
    "    'minority_group': ['1'] * 22267,\n",
    "    'screen_time_minutes': np.random.randint(0, 421, size=22267),\n",
    "    'wellbeing_score': np.random.rand(22267) * 10 \n",
    "}\n",
    "df = pd.DataFrame(minority_data)\n",
    "\n",
    "# Bin edges and labels\n",
    "bin_edges = [0, 120, 240, 421]\n",
    "bin_labels = ['0-2h', '2-4h', '4-7h']\n",
    "\n",
    "# Create bins for screen time\n",
    "df['screen_time_binned'] = pd.cut(df['screen_time_minutes'], bins=bin_edges, labels=bin_labels)\n",
    "\n",
    "# Filter for \"4-7h\"\n",
    "subgroup = df[df['screen_time_binned'] == '4-7h']\n",
    "\n",
    "# Correlation coefficient between screen time and wellbeing score\n",
    "correlation = subgroup['screen_time_minutes'].corr(subgroup['wellbeing_score'])\n",
    "\n",
    "print(\"Correlation coefficient for respondents who watched 4-7 hours of screen time:\", correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 3 | Rhemessa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Compare Screen Time of Deprived v. Non-Deprived\n",
    "Is there a notable difference of screen time hours between deprived and non-deprived respondents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Calculate screen time mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather screen time columns\n",
    "screentime = [\"C_we\", \"C_wk\", \"G_we\", \"G_wk\", \"S_we\", \"S_wk\", \"T_we\", \"T_wk\"]\n",
    "\n",
    "# Calculate mean\n",
    "merged_data['overall_screentime'] = merged_data[screentime].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Compare screen time by deprivation status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels for efficiency\n",
    "merged_data['deprivation_label'] = merged_data['deprived'].map({0: 'non_dep', 1: 'dep'})\n",
    "\n",
    "# Separate screen time by deprivation status\n",
    "non_deprivation = merged_data[merged_data['deprivation_label'] == 'non_dep']['overall_screentime']\n",
    "deprivation = merged_data[merged_data['deprivation_label'] == 'dep']['overall_screentime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Calculate the mean based on deprivation status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean for non-deprived group\n",
    "mean_non_dep = non_deprivation.mean()\n",
    "\n",
    "# Calculate the mean for deprived group\n",
    "mean_dep = deprivation.mean()\n",
    "\n",
    "print(\"Mean Overall Screen Time for Non-Deprived:\", mean_non_dep)\n",
    "print(\"Mean Overall Screen Time for Deprived:\", mean_dep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Visualise the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for mean comparison\n",
    "groups = ['Non-Deprived', 'Deprived']\n",
    "means = [mean_non_dep, mean_dep]\n",
    "\n",
    "plt.bar(groups, means, color=['#1f77b4', '#A3C1DA'])\n",
    "plt.ylabel('Mean Overall Screen Time')\n",
    "plt.title('Overall Screen Time for Non-Deprived vs Deprived Groups')\n",
    "for i, mean in enumerate(means):\n",
    "    plt.text(i, mean, f'{mean:.2f}', ha='center', va='bottom')\n",
    "plt.ylim(0, max(means) + 1) \n",
    "plt.show()\n",
    "\n",
    "# Histogram to show overall screen time\n",
    "hist_data = merged_data[['deprivation_label', 'overall_screentime']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(data=hist_data, x='overall_screentime', hue='deprivation_label', bins=7,\n",
    "             alpha=0.7, multiple='dodge', palette={'dep': '#A3C1DA', 'non_dep': '#1f77b4'})\n",
    "\n",
    "plt.title('Overall Screen Time by Hours')\n",
    "plt.xlabel('Overall Screen Time')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: The second histogram shows the data is skewed right, therefore it is not normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Perform Mann-Whitney U test\n",
    "* To understand if the difference in screen time were statistically significant, I opted to run the Mann-Whitney U test on the data. Because the data is not normally distributed it required a non-parametric test, thus the decision of the Mann-Whitney U."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_value = mannwhitneyu(deprivation, non_deprivation, alternative='two-sided')\n",
    "\n",
    "print(f'Mann-Whitney U statistic: {stat}')\n",
    "print(f'P-value: {p_value}')\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print('There is statistically signficant difference. Reject null hypothesis.')\n",
    "else:\n",
    "    print('There is no statistical significant difference between groups. Accept null hypothesis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion of Step 2\n",
    " Data indicates a difference in overall screen time. Respondents from deprived areas reported higher screentime than respondents in non-deprivation areas. The significance of difference in screen time was futher supported by the result of the Mann-Whitney U test where the null hypothesis was rejected. Additionally, deprived groups reported more hours on devices at the higher range (4, 5, 6 hours) than non-deprived groups who reported spending more hours on the lower range (1, 2, 3 hours). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Compare the Well-being Scores of Deprived v. Non-deprived Respondents\n",
    "Will the difference in screen time between deprived and non-deprived respondents result in a meaningful difference in well-being outcomes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Calculate and merge well-being mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of well-being columns\n",
    "wellbeing_cols = ['Optm', 'Usef', 'Relx', 'Intp', 'Engs', 'Dealpr', \n",
    "                  'Thcklr', 'Goodme', 'Clsep', 'Conf', 'Mkmind', \n",
    "                  'Loved', 'Intthg', 'Cheer']\n",
    "\n",
    "# Calculating the overall well-being\n",
    "merged_data['Overall_Wellbeing'] = merged_data[wellbeing_cols].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Compare well-being scores by deprivation status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels for efficiency\n",
    "merged_data['dep_status'] = merged_data['deprived'].map({0: 'non_dep', 1: 'dep'})\n",
    "\n",
    "# Separate well-being scores by deprivation\n",
    "non_depriv = merged_data[merged_data['dep_status'] == 'non_dep']['Overall_Wellbeing']\n",
    "depriv = merged_data[merged_data['dep_status'] == 'dep']['Overall_Wellbeing']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Calculate mean based on deprivation status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean for non-deprived group\n",
    "mean_non_deprived = non_depriv.mean()\n",
    "\n",
    "# Calculate the mean for deprived group\n",
    "mean_deprived = depriv.mean()\n",
    "\n",
    "print(\"Mean Overall Wellbeing for Non-Deprived:\", mean_non_deprived)\n",
    "print(\"Mean Overall Wellbeing for Deprived:\", mean_deprived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Visualise the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for overall well-being\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=merged_data, x='Overall_Wellbeing', hue='dep_status', multiple=\"dodge\", bins=15,\n",
    "             palette={'dep': '#A3C1DA', 'non_dep': '#1f77b4'})\n",
    "\n",
    "plt.title('Overall Wellbeing by Deprivation Status')\n",
    "plt.xlabel('Overall Wellbeing Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Bar plot for mean well-being\n",
    "groups = ['Non-Deprived', 'Deprived']\n",
    "means = [mean_non_deprived, mean_deprived]\n",
    "\n",
    "plt.bar(groups, means, color=['#1f77b4', '#A3C1DA'])\n",
    "plt.ylabel('Mean Well-being Screen Time')\n",
    "plt.title('Overall Well-being for Non-Deprived vs Deprived Groups')\n",
    "for i, mean in enumerate(means):\n",
    "    plt.text(i, mean, f'{mean:.2f}', ha='center', va='bottom')\n",
    "plt.ylim(0, max(means) + 1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: Histogram shows data is skewed left, therefore not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Perform Mann-Whitney U test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_value = mannwhitneyu(depriv, non_depriv, alternative='two-sided')\n",
    "\n",
    "print(f'Mann-Whitney U statistic: {stat}')\n",
    "print(f'P-value: {p_value}')\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print('There is a statistically signficant difference. Reject null hypothesis.')\n",
    "else:\n",
    "    print('There is no statistical significance in the difference between groups. Accept null hypothesis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion of Step 3:\n",
    "* Note: The well-being scores based on deprivation status indicate that respondents from areas with high deprivation reported slightly lower well-being scores. The statistical significance is confirmed by the non-parametric Mann-Whitney U test. The histogram is skewed left, indicating the data is not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Analysing the Distribution of the Results\n",
    "Confirming how the data is distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Checking screen time data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = merged_data['overall_screentime'].sample(5000, random_state=1)\n",
    "\n",
    "stat, p_value = shapiro(sample)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Data is not normally distributed\")\n",
    "    print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Checking well-being data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = merged_data['Overall_Wellbeing'].sample(5000, random_state=1)\n",
    "\n",
    "stat, p_value = shapiro(sample)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Data is not normally distributed\")\n",
    "    print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Conclusion:\n",
    "As indicated by the relevant histograms, the data for both well-being scores and screen time is confirmed to be not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Isolating and Transforming the Data for Deprived Respondents\n",
    "Since the data required for our predictive modelling is not normally distributed, it may help to transform it. Transforming data that is not normally distributed can pull it as close to normal distribution as possible. This can provide better results from our predictive modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Creating a DataFrame copy to isolate values of deprived respondents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate and store deprivation data in variable\n",
    "isolated_dep = merged_data[merged_data['deprived'] == 1]\n",
    "\n",
    "n = len(isolated_dep)\n",
    "print(\"The sample size is: %d\" % n)\n",
    "\n",
    "print(isolated_dep.columns)\n",
    "\n",
    "# Creating a new data frame with the required values\n",
    "iso_df = isolated_dep.copy()\n",
    "\n",
    "iso_df['iso_wb'] = isolated_dep[['Optm', 'Usef', 'Relx', 'Intp', 'Engs', 'Dealpr', \n",
    "                  'Thcklr', 'Goodme', 'Clsep', 'Conf', 'Mkmind', \n",
    "                  'Loved', 'Intthg', 'Cheer']].mean(axis=1)\n",
    "\n",
    "iso_df['iso_st'] = isolated_dep[[\"C_we\", \"C_wk\", \"G_we\", \"G_wk\", \"S_we\", \"S_wk\", \"T_we\", \"T_wk\"]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Verifying the sample size and means against previous results to ensure we are working with the correct data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the sample size \n",
    "n = len(iso_df)\n",
    "print(\"The sample size is: %d\" % n)\n",
    "\n",
    "# Verify wellbeing mean\n",
    "mean_wb = iso_df['iso_wb'].mean()\n",
    "print(mean_wb)\n",
    "# Verify screentime mean\n",
    "mean_st = iso_df['iso_st'].mean()\n",
    "print(mean_st)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Transforming data, re-evaluating, and visualising data distributions before and after log and square root transformations\n",
    "* Note: Re-evaluating and visualising the data assists in deciding which data set (original data, log transformed, square root transformed) is closest to normal distribution. This will indicate which data will provide the best outcomes from the predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.1. Transformation and visualisation of screen time data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For the screen time data, a log transformation may work best as the data is skewed right and the log transformation will pull the data right. This can assist in distributing the data normally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOG TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation screen time\n",
    "iso_df['log_iso_st'] = np.log(iso_df['iso_st'] + 1)\n",
    "\n",
    "# Re-evaluating distribution (decided to use a smaller sample size for this test for accuracy)\n",
    "sample = iso_df['log_iso_st'].sample(5000, random_state=1)\n",
    "stat, p_value = shapiro(sample)\n",
    "if p_value < 0.05:\n",
    "    print(\"Data is not normally distributed\")\n",
    "    print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQUARE ROOT TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square root transformation screen time\n",
    "iso_df['sqrt_iso_st'] = np.sqrt(iso_df['iso_st'])\n",
    "\n",
    "# Re-evaluating distribution (decided to use a smaller sample size for this test for accuracy)\n",
    "sample = iso_df['sqrt_iso_st'].sample(5000, random_state=1)\n",
    "stat, p_value = shapiro(sample)\n",
    "if p_value < 0.05:\n",
    "    print(\"Data is not normally distributed\")\n",
    "    print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ORIGINAL SCREEN TIME DATA VISUALISATION #####\n",
    "sns.histplot(iso_df['iso_st'], bins=14, kde=True)\n",
    "\n",
    "plt.xlabel('Screen Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Original Screen Time Data')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LOG TRANSFORMED SCREEN TIME DATA VISUALISATION #####\n",
    "sns.histplot(iso_df['log_iso_st'], bins=14, kde=True)\n",
    "\n",
    "plt.xlabel('Screen Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Log Screen Time')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SQUARE ROOT TRANSFORMED SCREEN TIME DATA VISUALISATION #####\n",
    "sns.histplot(iso_df['sqrt_iso_st'], bins=14, kde=True)\n",
    "\n",
    "\n",
    "plt.xlabel('Screen Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SqRt Screen Time')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.2. Transformation and visualisation of well-being data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQUARE ROOT TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square root transformation well-being\n",
    "iso_df['sqrt_iso_wb'] = np.sqrt(iso_df['iso_wb'])\n",
    "\n",
    "# Re-evaluating distribution (decided to use a smaller sample size for this test for accuracy)\n",
    "sample = iso_df['sqrt_iso_wb'].sample(5000, random_state=1)\n",
    "stat, p_value = shapiro(sample)\n",
    "if p_value < 0.05:\n",
    "    print(\"Data is not normally distributed\")\n",
    "    print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOG TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation well-being\n",
    "iso_df['log_iso_wb'] = np.log(iso_df['iso_wb'] + 1)\n",
    "\n",
    "# Re-evaluating distribution (decided to use a smaller sample size for this test for accuracy)\n",
    "sample = iso_df['log_iso_wb'].sample(5000, random_state=1)\n",
    "stat, p_value = shapiro(sample)\n",
    "if p_value < 0.05:\n",
    "    print(\"Data is not normally distributed\")\n",
    "    print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ORIGINAL WELL-BEING DATA VISUALISATION #####\n",
    "sns.histplot(iso_df['iso_wb'], bins=15, kde=True)\n",
    "\n",
    "plt.xlabel('Well-being')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Original Well-being')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SQUARE ROOT TRANSFORMED WELLBEING DATA VISUALISATION #####\n",
    "sns.histplot(iso_df['sqrt_iso_wb'], bins=15, kde=True)\n",
    "\n",
    "plt.xlabel('Well-being')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SqRt Well-being')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LOG TRANSFORMED WELLBEING DATA VISUALISATION #####\n",
    "sns.histplot(iso_df['log_iso_wb'], bins=15, kde=True)\n",
    "\n",
    "plt.xlabel('Well-being')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Log Well-being')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 Conclusion: \n",
    "Based on the p-value results of the Shapiro-Wilks test after performing the transformations, the log transformations had the best outcome in distribution. Therefore, the log transformations will work best for the predictive model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Generate and analyse correlation matrix\n",
    "* I chose to generate a correlation matrix to futher my understanding of the relationship between the two variables I wanted to isolate for my predictive model. The correlation matrix is a simple method that provides insight into the relationship between the two variables, how they interact with each other, and what trend/pattern they produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix for the specified columns\n",
    "correlation_matrix = iso_df[['log_iso_st', 'log_iso_wb']].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: The results of the correlation matrix show little to no correlation, linear or otherwise, between my two variables. Therefore, a linear regression model will not fit my analysis. For the purpose of a predictive model, a tree model will work best for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Generate scatter plot for futher visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='log_iso_wb', y='log_iso_st', data=iso_df, height=6, aspect=1.25, scatter_kws={'s': 2.5})\n",
    "plt.xlabel('Well-being')\n",
    "plt.ylabel('Screen Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Generate Decision Tree Regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = iso_df[['log_iso_wb']]\n",
    "y = iso_df['log_iso_st']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=30)\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=10, min_samples_split=5, random_state=5)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)\n",
    "sqrt_mse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(sqrt_mse)\n",
    "r2 = r2_score(y_pred, y_test)\n",
    "print(r2)\n",
    "\n",
    "cross_val_score(dt, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Generate scatterplot to visualise predictions of Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, color='#A3C1DA', alpha=0.6, edgecolors='#1f77b4')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--') \n",
    "plt.title('Actual vs Predicted')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.xlim(y.min(), y.max())\n",
    "plt.ylim(y.min(), y.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: Visualisation suggests the model is not learning effectively to provide meaningful predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion of Step 6:\n",
    "After running the correlation matrix and finding little to no correlation between my data, I opted to use a tree model for my predictive model. Testing of the Decision Tree Regressor model produced result that were less than favourable in terms of predicting outcomes. This can be due to many reasons such as irrelevant data, overfitting or underfitting, and the feature engineering process. For more accurate predicitions there is potential to further analyse or optimise the data for better predictive outcomes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 4 | Jabed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Exploring Screen Time Activities\n",
    "#Calculate average screen time for each activity (Gaming, Smartphone, TV, Computer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean screen time for each activity (combining weekday and weekend)\n",
    "smartphone_mean = dataset2[['S_we', 'S_wk']].mean(axis=1).mean()\n",
    "tv_mean = dataset2[['T_we', 'T_wk']].mean(axis=1).mean()\n",
    "computer_mean = dataset2[['C_we', 'C_wk']].mean(axis=1).mean()\n",
    "gaming_mean = dataset2[['G_we', 'G_wk']].mean(axis=1).mean()\n",
    "\n",
    "# Print the results\n",
    "print(f'Smartphone Mean: {smartphone_mean} hours')\n",
    "print(f'TV Mean: {tv_mean} hours')\n",
    "print(f'Computer Mean: {computer_mean} hours')\n",
    "print(f'Gaming Mean: {gaming_mean} hours')\n",
    "\n",
    "# Create histograms for each activity (weekend and weekday combined)\n",
    "activities = {\n",
    "    'Smartphone': dataset2[['S_we', 'S_wk']].mean(axis=1),\n",
    "    'TV': dataset2[['T_we', 'T_wk']].mean(axis=1),\n",
    "    'Computer': dataset2[['C_we', 'C_wk']].mean(axis=1),\n",
    "    'Gaming': dataset2[['G_we', 'G_wk']].mean(axis=1)\n",
    "}\n",
    "\n",
    "# Plot histograms\n",
    "for activity, data in activities.items():\n",
    "    plt.figure()\n",
    "    plt.hist(data, bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.title(f'Histogram of {activity} Screen Time')\n",
    "    plt.xlabel('Hours per Day')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Prepare the data for the box plots by combining weekday and weekend screen time for each activity\n",
    "data = {\n",
    "    'Smartphone': dataset2[['S_we', 'S_wk']].mean(axis=1),\n",
    "    'TV': dataset2[['T_we', 'T_wk']].mean(axis=1),\n",
    "    'Computer': dataset2[['C_we', 'C_wk']].mean(axis=1),\n",
    "    'Gaming': dataset2[['G_we', 'G_wk']].mean(axis=1)\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easier plotting\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a box plot for each screen time activity\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.boxplot()\n",
    "plt.title('Box Plot of Screen Time Activities')\n",
    "plt.ylabel('Hours per Day')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Focusing on meaningful scatter plots only\n",
    "# Plot Total Screen Time vs Overall Well-being\n",
    "merged_data['Total_Screen_Time'] = merged_data[['C_we', 'C_wk', 'G_we', 'G_wk', 'S_we', 'S_wk', 'T_we', 'T_wk']].sum(axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(merged_data['Total_Screen_Time'], merged_data['Overall_Wellbeing'], alpha=0.5, color='blue')\n",
    "plt.title('Total Screen Time vs Overall Well-being')\n",
    "plt.xlabel('Total Screen Time (Hours per Week)')\n",
    "plt.ylabel('Overall Well-being Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate Average Screen Time for Each Activity\n",
    "average_screen_time = merged_data[['C_wk', 'C_we', 'G_wk', 'G_we', 'S_wk', 'S_we', 'T_wk', 'T_we']].mean()\n",
    "print(\"Average Screen Time for Each Activity:\\n\", average_screen_time)\n",
    "\n",
    "# Step 2: Generate Descriptive Statistics for Each Activity\n",
    "screen_time_stats = merged_data[['C_wk', 'C_we', 'G_wk', 'G_we', 'S_wk', 'S_we', 'T_wk', 'T_we']].describe()\n",
    "print(\"Descriptive Statistics for Screen Time Activities:\\n\", screen_time_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Calculate the Overall Well-being Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated overall well-being score as the mean of well-being indicators\n",
    "merged_data['Overall_Wellbeing'] = merged_data[['Optm', 'Usef', 'Relx', 'Intp', 'Engs', 'Dealpr', 'Thcklr', 'Goodme', 'Clsep', 'Conf', 'Mkmind', 'Loved', 'Intthg', 'Cheer']].mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target variable\n",
    "X = merged_data[['T_we']]  # TV usage on weekends as the predictor\n",
    "y = merged_data['Overall_Wellbeing']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build the Predictive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training the linear regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'R^2 Score: {r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for actual vs predicted well-being scores\n",
    "plt.scatter(y_test, y_pred, color='blue')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Actual Well-being Score')\n",
    "plt.ylabel('Predicted Well-being Score')\n",
    "plt.title('Actual vs Predicted Well-being Score')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grp_pres",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
